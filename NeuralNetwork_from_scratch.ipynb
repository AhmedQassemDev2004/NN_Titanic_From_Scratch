{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  ...     Fare Cabin  Embarked\n",
       "0            1         0       3  ...   7.2500   NaN         S\n",
       "1            2         1       1  ...  71.2833   C85         C\n",
       "2            3         1       3  ...   7.9250   NaN         S\n",
       "3            4         1       1  ...  53.1000  C123         S\n",
       "4            5         0       3  ...   8.0500   NaN         S\n",
       "\n",
       "[5 rows x 12 columns]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/titanic.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passengerid</th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>name</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>ticket</th>\n",
       "      <th>fare</th>\n",
       "      <th>cabin</th>\n",
       "      <th>embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   passengerid  survived  pclass  ...     fare cabin  embarked\n",
       "0            1         0       3  ...   7.2500   NaN         S\n",
       "1            2         1       1  ...  71.2833   C85         C\n",
       "2            3         1       3  ...   7.9250   NaN         S\n",
       "3            4         1       1  ...  53.1000  C123         S\n",
       "4            5         0       3  ...   8.0500   NaN         S\n",
       "\n",
       "[5 rows x 12 columns]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns = df.columns.str.lower()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "survived    891\n",
       "pclass      891\n",
       "sex         891\n",
       "age         891\n",
       "sibsp       891\n",
       "parch       891\n",
       "fare        891\n",
       "embarked    891\n",
       "dtype: int64"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop(columns=['name', 'passengerid', 'ticket', 'cabin'])\n",
    "df.isna().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>sex_female</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>embarked_C</th>\n",
       "      <th>embarked_Q</th>\n",
       "      <th>embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   survived  pclass   age  sibsp  ...  sex_male  embarked_C  embarked_Q  embarked_S\n",
       "0         0       3  22.0      1  ...      True       False       False        True\n",
       "1         1       1  38.0      1  ...     False        True       False       False\n",
       "2         1       3  26.0      0  ...     False       False       False        True\n",
       "3         1       1  35.0      1  ...     False       False       False        True\n",
       "4         0       3  35.0      0  ...      True       False       False        True\n",
       "\n",
       "[5 rows x 11 columns]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['embarked']= df['embarked'].fillna(df['embarked'].mode())\n",
    "df['age'] = df['age'].fillna(df['age'].mean())\n",
    "df = pd.get_dummies(df, columns=['sex', 'embarked'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['survived'].values.reshape(-1, 1)  \n",
    "X = df.drop(columns=['survived'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>sex_female</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>embarked_C</th>\n",
       "      <th>embarked_Q</th>\n",
       "      <th>embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.827377</td>\n",
       "      <td>-0.592481</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.502445</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.566107</td>\n",
       "      <td>0.638789</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.786845</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.827377</td>\n",
       "      <td>-0.284663</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.488854</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.566107</td>\n",
       "      <td>0.407926</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.420730</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.827377</td>\n",
       "      <td>0.407926</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.486337</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>-0.369365</td>\n",
       "      <td>-0.207709</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.386671</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>-1.566107</td>\n",
       "      <td>-0.823344</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.044381</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>0.827377</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.176263</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>-1.566107</td>\n",
       "      <td>-0.284663</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.044381</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>0.827377</td>\n",
       "      <td>0.177063</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.492378</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       pclass       age  sibsp  ...  embarked_C  embarked_Q  embarked_S\n",
       "0    0.827377 -0.592481    1.0  ...         0.0         0.0         1.0\n",
       "1   -1.566107  0.638789    1.0  ...         1.0         0.0         0.0\n",
       "2    0.827377 -0.284663    0.0  ...         0.0         0.0         1.0\n",
       "3   -1.566107  0.407926    1.0  ...         0.0         0.0         1.0\n",
       "4    0.827377  0.407926    0.0  ...         0.0         0.0         1.0\n",
       "..        ...       ...    ...  ...         ...         ...         ...\n",
       "886 -0.369365 -0.207709    0.0  ...         0.0         0.0         1.0\n",
       "887 -1.566107 -0.823344    0.0  ...         0.0         0.0         1.0\n",
       "888  0.827377  0.000000    1.0  ...         0.0         0.0         1.0\n",
       "889 -1.566107 -0.284663    0.0  ...         1.0         0.0         0.0\n",
       "890  0.827377  0.177063    0.0  ...         0.0         1.0         0.0\n",
       "\n",
       "[891 rows x 10 columns]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "numeric_cols = ['pclass', 'age', 'fare']\n",
    "X[numeric_cols] = scaler.fit_transform(X[numeric_cols])\n",
    "\n",
    "X = X.astype(float)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing Neural Network From Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_params(input_size):\n",
    "    params = {}\n",
    "    params['W1'] = np.random.randn(input_size, 64) * np.sqrt(1 / input_size)\n",
    "    params['W2'] = np.random.randn(64, 32) * np.sqrt(1 / 64)\n",
    "    params['W3'] = np.random.randn(32, 16) * np.sqrt(1 / 32)\n",
    "    params['W4'] = np.random.randn(16, 1) * np.sqrt(1 / 16)\n",
    "    \n",
    "    params['b1'] = np.zeros((1, 64))\n",
    "    params['b2'] = np.zeros((1, 32))\n",
    "    params['b3'] = np.zeros((1, 16))\n",
    "    params['b4'] = np.zeros((1, 1))\n",
    "\n",
    "    for key in ['W1', 'W2', 'W3', 'W4', 'b1', 'b2', 'b3', 'b4']:\n",
    "        params[f'm_{key}'] = np.zeros_like(params[key])\n",
    "        params[f'v_{key}'] = np.zeros_like(params[key])\n",
    "\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReLU(Z):\n",
    "    return np.maximum(1, Z)\n",
    "\n",
    "def sigmoid(Z):\n",
    "    Z = np.asarray(Z, dtype=np.float64)  # Ensure Z is a NumPy array with float64 dtype\n",
    "    Z = np.clip(Z, -500, 500)  # Adjust these limits as needed\n",
    "    return 1 / (1 + np.exp(-Z))\n",
    "\n",
    "def forward_prop(X, params, keep_prob=1.0):\n",
    "    cache = {} \n",
    "\n",
    "    Z1 = np.dot(X, params['W1']) + params['b1']\n",
    "    A1 = ReLU(Z1)\n",
    "\n",
    "    if keep_prob < 1.0:\n",
    "        D1 = np.random.randn(*A1.shape) < keep_prob\n",
    "        A1 *= D1 \n",
    "        A1 /= keep_prob\n",
    "        cache['D1'] = D1\n",
    "    \n",
    "    Z2 = np.dot(A1, params['W2']) + params['b2']\n",
    "    A2 = ReLU(Z2)\n",
    "\n",
    "    if keep_prob < 1.0:\n",
    "        D2 = np.random.rand(*A2.shape) < keep_prob\n",
    "        A2 *= D2\n",
    "        A2 /= keep_prob\n",
    "        cache['D2'] = D2\n",
    "\n",
    "    Z3 = np.dot(A2, params['W3']) + params['b3']\n",
    "    A3 = sigmoid(Z3)\n",
    "    \n",
    "\n",
    "    cache['Z1'], cache['A1'], cache['Z2'], cache['A2'], cache['Z3'], cache['A3'] = Z1, A1, Z2, A2, Z3, A3\n",
    "\n",
    "    return A3, cache\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mini_batches(X, y, batch_size=32):\n",
    "    batches = []\n",
    "    m = X.shape[0]  # Number of samples\n",
    "\n",
    "    permutation = np.random.permutation(m)  # Shuffle indices\n",
    "\n",
    "    X, y = np.array(X), np.array(y)\n",
    "    X_shuffled = X[permutation]\n",
    "    y_shuffled = y[permutation]  \n",
    "\n",
    "    num_batches = m // batch_size\n",
    "\n",
    "    for i in range(num_batches):\n",
    "        X_mini = X_shuffled[i * batch_size:(i + 1) * batch_size]\n",
    "        y_mini = y_shuffled[i * batch_size:(i + 1) * batch_size]\n",
    "        batches.append((X_mini, y_mini))\n",
    "\n",
    "    if m % batch_size != 0:  # Add remaining samples if any\n",
    "        X_mini = X_shuffled[num_batches * batch_size:]\n",
    "        y_mini = y_shuffled[num_batches * batch_size:]\n",
    "        batches.append((X_mini, y_mini))\n",
    "\n",
    "    return batches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(y_pred, y, params, lambda_reg=0.01):\n",
    "    m = y.shape[0]\n",
    "    cross_entropy_loss = 1/m * np.sum(-y*np.log(y_pred+1e-10)+(1-y)*np.log(1-y_pred+1e-10))\n",
    "    l2_loss = lambda_reg * (np.sum(params['W1']**2) + np.sum(params['W2']**2) + np.sum(params['W3']**2))\n",
    "    return cross_entropy_loss + l2_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def back_prop(X, y, params, cache, keep_prob=1.0):\n",
    "   \n",
    "    m = X.shape[0]  # Number of samples\n",
    "    grads = {}\n",
    "\n",
    "    A1, A2, A3 = cache['A1'], cache['A2'], cache['A3']\n",
    "    Z1, Z2, Z3 = cache['Z1'], cache['Z2'], cache['Z3']\n",
    "\n",
    "    dZ3 = A3 - y  # Derivative of binary cross-entropy loss w.r.t Z3\n",
    "    dW3 = (1/m) * np.dot(A2.T, dZ3)\n",
    "    db3 = (1/m) * np.sum(dZ3, axis=0, keepdims=True)\n",
    "\n",
    "    dA2 = np.dot(dZ3, params['W3'].T)\n",
    "    dZ2 = dA2 * (Z2 > 0)  # ReLU derivative\n",
    "    dW2 = (1/m) * np.dot(A1.T, dZ2)\n",
    "    db2 = (1/m) * np.sum(dZ2, axis=0, keepdims=True)\n",
    "\n",
    "    if keep_prob < 1.0:\n",
    "        dA2 *= cache['D2']\n",
    "        dA2 /= keep_prob\n",
    "\n",
    "    dA1 = np.dot(dZ2, params['W2'].T)\n",
    "    dZ1 = dA1 * (Z1 > 0)  # ReLU derivative\n",
    "    dW1 = (1/m) * np.dot(X.T, dZ1)\n",
    "    db1 = (1/m) * np.sum(dZ1, axis=0, keepdims=True)\n",
    "\n",
    "    if keep_prob < 1.0:\n",
    "        dA1 *= cache['D1']\n",
    "        dA1 /= keep_prob\n",
    "\n",
    "    grads['dW1'], grads['db1'] = dW1, db1\n",
    "    grads['dW2'], grads['db2'] = dW2, db2\n",
    "    grads['dW3'], grads['db3'] = dW3, db3\n",
    "\n",
    "    return grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_params(params, grads, learning_rate=0.01, beta1=0.9, beta2=0.999, epsilon=1e-8, t=1):\n",
    "    updated_params = params.copy()  # Create a copy of params to avoid modifying the original\n",
    "\n",
    "    # Update first and second moments for weights and biases\n",
    "    for key in ['W1', 'W2', 'W3', 'b1', 'b2', 'b3']:\n",
    "        # Update first moment (momentum)\n",
    "        updated_params[f'm_{key}'] = beta1 * params[f'm_{key}'] + (1 - beta1) * grads[f'd{key}']\n",
    "        \n",
    "        # Update second moment (RMSprop)\n",
    "        updated_params[f'v_{key}'] = beta2 * params[f'v_{key}'] + (1 - beta2) * (grads[f'd{key}'] ** 2)\n",
    "        \n",
    "        # Bias correction for first and second moments\n",
    "        m_hat = updated_params[f'm_{key}'] / (1 - beta1 ** t)\n",
    "        v_hat = updated_params[f'v_{key}'] / (1 - beta2 ** t)\n",
    "        \n",
    "        # Update parameters\n",
    "        updated_params[key] = params[key] - learning_rate * m_hat / (np.sqrt(v_hat) + epsilon)\n",
    "\n",
    "    return updated_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X, y, params, epochs, decay_rate=0.2, learning_rate=0.01, batch_size=32, keep_prob=0.8, beta1=0.09, beta2=0.999):\n",
    "    learning_rate0 = learning_rate\n",
    "    t = 1  # Initialize time step for Adam\n",
    "\n",
    "    for i in range(epochs):\n",
    "        batches = create_mini_batches(X, y, batch_size=batch_size)\n",
    "        epoch_loss = 0  \n",
    "\n",
    "        for X_mini, y_mini in batches:\n",
    "            A3, cache = forward_prop(X_mini, params, keep_prob)\n",
    "            loss = compute_loss(A3, y_mini, params)\n",
    "            epoch_loss += loss  \n",
    "            grads = back_prop(X_mini, y_mini, params, cache, keep_prob)\n",
    "            params = update_params(params, grads, learning_rate, beta1, beta2, t)\n",
    "            t += 1  # Increment time step\n",
    "        \n",
    "        learning_rate = (1 / (1 + decay_rate * i)) * learning_rate0\n",
    "        epoch_loss /= len(batches)\n",
    "\n",
    "        if (i + 1) % 100 == 0:\n",
    "            print(f\"Epoch {i + 1} Done\")\n",
    "            print(\"Learning rate: \", learning_rate)\n",
    "\n",
    "    return params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = forward_prop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing params:  {'learning_rate': 0.001, 'keep_prob': 0.9, 'decay_rate': 0.01, 'beta2': 0.999, 'beta1': 0.9, 'batch_size': 64}\n",
      "Epoch 100 Done\n",
      "Learning rate:  0.0005025125628140703\n",
      "Epoch 200 Done\n",
      "Learning rate:  0.00033444816053511704\n",
      "Epoch 300 Done\n",
      "Learning rate:  0.0002506265664160401\n",
      "Epoch 400 Done\n",
      "Learning rate:  0.00020040080160320639\n",
      "Epoch 500 Done\n",
      "Learning rate:  0.0001669449081803005\n",
      "Epoch 600 Done\n",
      "Learning rate:  0.00014306151645207438\n",
      "Epoch 700 Done\n",
      "Learning rate:  0.0001251564455569462\n",
      "Epoch 800 Done\n",
      "Learning rate:  0.00011123470522803114\n",
      "Epoch 900 Done\n",
      "Learning rate:  0.00010010010010010009\n",
      "Epoch 1000 Done\n",
      "Learning rate:  9.099181073703367e-05\n",
      "Epoch 1100 Done\n",
      "Learning rate:  8.340283569641367e-05\n",
      "Epoch 1200 Done\n",
      "Learning rate:  7.698229407236336e-05\n",
      "Epoch 1300 Done\n",
      "Learning rate:  7.14796283059328e-05\n",
      "Epoch 1400 Done\n",
      "Learning rate:  6.6711140760507e-05\n",
      "Epoch 1500 Done\n",
      "Learning rate:  6.253908692933083e-05\n",
      "Epoch 1600 Done\n",
      "Learning rate:  5.8858151854031775e-05\n",
      "Epoch 1700 Done\n",
      "Learning rate:  5.558643690939411e-05\n",
      "Epoch 1800 Done\n",
      "Learning rate:  5.26592943654555e-05\n",
      "Epoch 1900 Done\n",
      "Learning rate:  5.002501250625312e-05\n",
      "Epoch 2000 Done\n",
      "Learning rate:  4.764173415912339e-05\n",
      "Validation Accuracy: 58.35%\n",
      "Testing params:  {'learning_rate': 0.001, 'keep_prob': 0.7, 'decay_rate': 0.0, 'beta2': 0.999, 'beta1': 0.9, 'batch_size': 64}\n",
      "Epoch 100 Done\n",
      "Learning rate:  0.001\n",
      "Epoch 200 Done\n",
      "Learning rate:  0.001\n",
      "Epoch 300 Done\n",
      "Learning rate:  0.001\n",
      "Epoch 400 Done\n",
      "Learning rate:  0.001\n",
      "Epoch 500 Done\n",
      "Learning rate:  0.001\n",
      "Epoch 600 Done\n",
      "Learning rate:  0.001\n",
      "Epoch 700 Done\n",
      "Learning rate:  0.001\n",
      "Epoch 800 Done\n",
      "Learning rate:  0.001\n",
      "Epoch 900 Done\n",
      "Learning rate:  0.001\n",
      "Epoch 1000 Done\n",
      "Learning rate:  0.001\n",
      "Epoch 1100 Done\n",
      "Learning rate:  0.001\n",
      "Epoch 1200 Done\n",
      "Learning rate:  0.001\n",
      "Epoch 1300 Done\n",
      "Learning rate:  0.001\n",
      "Epoch 1400 Done\n",
      "Learning rate:  0.001\n",
      "Epoch 1500 Done\n",
      "Learning rate:  0.001\n",
      "Epoch 1600 Done\n",
      "Learning rate:  0.001\n",
      "Epoch 1700 Done\n",
      "Learning rate:  0.001\n",
      "Epoch 1800 Done\n",
      "Learning rate:  0.001\n",
      "Epoch 1900 Done\n",
      "Learning rate:  0.001\n",
      "Epoch 2000 Done\n",
      "Learning rate:  0.001\n",
      "Validation Accuracy: 60.80%\n",
      "Testing params:  {'learning_rate': 0.1, 'keep_prob': 0.7, 'decay_rate': 0.0, 'beta2': 0.995, 'beta1': 0.9, 'batch_size': 64}\n",
      "Epoch 100 Done\n",
      "Learning rate:  0.1\n",
      "Epoch 200 Done\n",
      "Learning rate:  0.1\n",
      "Epoch 300 Done\n",
      "Learning rate:  0.1\n",
      "Epoch 400 Done\n",
      "Learning rate:  0.1\n",
      "Epoch 500 Done\n",
      "Learning rate:  0.1\n",
      "Epoch 600 Done\n",
      "Learning rate:  0.1\n",
      "Epoch 700 Done\n",
      "Learning rate:  0.1\n",
      "Epoch 800 Done\n",
      "Learning rate:  0.1\n",
      "Epoch 900 Done\n",
      "Learning rate:  0.1\n",
      "Epoch 1000 Done\n",
      "Learning rate:  0.1\n",
      "Epoch 1100 Done\n",
      "Learning rate:  0.1\n",
      "Epoch 1200 Done\n",
      "Learning rate:  0.1\n",
      "Epoch 1300 Done\n",
      "Learning rate:  0.1\n",
      "Epoch 1400 Done\n",
      "Learning rate:  0.1\n",
      "Epoch 1500 Done\n",
      "Learning rate:  0.1\n",
      "Epoch 1600 Done\n",
      "Learning rate:  0.1\n",
      "Epoch 1700 Done\n",
      "Learning rate:  0.1\n",
      "Epoch 1800 Done\n",
      "Learning rate:  0.1\n",
      "Epoch 1900 Done\n",
      "Learning rate:  0.1\n",
      "Epoch 2000 Done\n",
      "Learning rate:  0.1\n",
      "Validation Accuracy: 66.74%\n",
      "Testing params:  {'learning_rate': 0.001, 'keep_prob': 0.7, 'decay_rate': 0.001, 'beta2': 0.999, 'beta1': 0.9, 'batch_size': 32}\n",
      "Epoch 100 Done\n",
      "Learning rate:  0.0009099181073703368\n",
      "Epoch 200 Done\n",
      "Learning rate:  0.0008340283569641367\n",
      "Epoch 300 Done\n",
      "Learning rate:  0.0007698229407236335\n",
      "Epoch 400 Done\n",
      "Learning rate:  0.0007147962830593281\n",
      "Epoch 500 Done\n",
      "Learning rate:  0.0006671114076050701\n",
      "Epoch 600 Done\n",
      "Learning rate:  0.0006253908692933083\n",
      "Epoch 700 Done\n",
      "Learning rate:  0.0005885815185403178\n",
      "Epoch 800 Done\n",
      "Learning rate:  0.0005558643690939412\n",
      "Epoch 900 Done\n",
      "Learning rate:  0.000526592943654555\n",
      "Epoch 1000 Done\n",
      "Learning rate:  0.0005002501250625312\n",
      "Epoch 1100 Done\n",
      "Learning rate:  0.0004764173415912339\n",
      "Epoch 1200 Done\n",
      "Learning rate:  0.0004547521600727604\n",
      "Epoch 1300 Done\n",
      "Learning rate:  0.00043497172683775554\n",
      "Epoch 1400 Done\n",
      "Learning rate:  0.00041684035014589413\n",
      "Epoch 1500 Done\n",
      "Learning rate:  0.0004001600640256102\n",
      "Epoch 1600 Done\n",
      "Learning rate:  0.0003847633705271258\n",
      "Epoch 1700 Done\n",
      "Learning rate:  0.0003705075954057058\n",
      "Epoch 1800 Done\n",
      "Learning rate:  0.0003572704537334763\n",
      "Epoch 1900 Done\n",
      "Learning rate:  0.0003449465332873405\n",
      "Epoch 2000 Done\n",
      "Learning rate:  0.00033344448149383126\n",
      "Validation Accuracy: 60.93%\n",
      "Testing params:  {'learning_rate': 0.001, 'keep_prob': 0.7, 'decay_rate': 0.01, 'beta2': 0.999, 'beta1': 0.95, 'batch_size': 64}\n",
      "Epoch 100 Done\n",
      "Learning rate:  0.0005025125628140703\n",
      "Epoch 200 Done\n",
      "Learning rate:  0.00033444816053511704\n",
      "Epoch 300 Done\n",
      "Learning rate:  0.0002506265664160401\n",
      "Epoch 400 Done\n",
      "Learning rate:  0.00020040080160320639\n",
      "Epoch 500 Done\n",
      "Learning rate:  0.0001669449081803005\n",
      "Epoch 600 Done\n",
      "Learning rate:  0.00014306151645207438\n",
      "Epoch 700 Done\n",
      "Learning rate:  0.0001251564455569462\n",
      "Epoch 800 Done\n",
      "Learning rate:  0.00011123470522803114\n",
      "Epoch 900 Done\n",
      "Learning rate:  0.00010010010010010009\n",
      "Epoch 1000 Done\n",
      "Learning rate:  9.099181073703367e-05\n",
      "Epoch 1100 Done\n",
      "Learning rate:  8.340283569641367e-05\n",
      "Epoch 1200 Done\n",
      "Learning rate:  7.698229407236336e-05\n",
      "Epoch 1300 Done\n",
      "Learning rate:  7.14796283059328e-05\n",
      "Epoch 1400 Done\n",
      "Learning rate:  6.6711140760507e-05\n",
      "Epoch 1500 Done\n",
      "Learning rate:  6.253908692933083e-05\n",
      "Epoch 1600 Done\n",
      "Learning rate:  5.8858151854031775e-05\n",
      "Epoch 1700 Done\n",
      "Learning rate:  5.558643690939411e-05\n",
      "Epoch 1800 Done\n",
      "Learning rate:  5.26592943654555e-05\n",
      "Epoch 1900 Done\n",
      "Learning rate:  5.002501250625312e-05\n",
      "Epoch 2000 Done\n",
      "Learning rate:  4.764173415912339e-05\n",
      "Validation Accuracy: 60.80%\n",
      "Testing params:  {'learning_rate': 0.001, 'keep_prob': 0.7, 'decay_rate': 0.01, 'beta2': 0.999, 'beta1': 0.9, 'batch_size': 64}\n",
      "Epoch 100 Done\n",
      "Learning rate:  0.0005025125628140703\n",
      "Epoch 200 Done\n",
      "Learning rate:  0.00033444816053511704\n",
      "Epoch 300 Done\n",
      "Learning rate:  0.0002506265664160401\n",
      "Epoch 400 Done\n",
      "Learning rate:  0.00020040080160320639\n",
      "Epoch 500 Done\n",
      "Learning rate:  0.0001669449081803005\n",
      "Epoch 600 Done\n",
      "Learning rate:  0.00014306151645207438\n",
      "Epoch 700 Done\n",
      "Learning rate:  0.0001251564455569462\n",
      "Epoch 800 Done\n",
      "Learning rate:  0.00011123470522803114\n",
      "Epoch 900 Done\n",
      "Learning rate:  0.00010010010010010009\n",
      "Epoch 1000 Done\n",
      "Learning rate:  9.099181073703367e-05\n",
      "Epoch 1100 Done\n",
      "Learning rate:  8.340283569641367e-05\n",
      "Epoch 1200 Done\n",
      "Learning rate:  7.698229407236336e-05\n",
      "Epoch 1300 Done\n",
      "Learning rate:  7.14796283059328e-05\n",
      "Epoch 1400 Done\n",
      "Learning rate:  6.6711140760507e-05\n",
      "Epoch 1500 Done\n",
      "Learning rate:  6.253908692933083e-05\n",
      "Epoch 1600 Done\n",
      "Learning rate:  5.8858151854031775e-05\n",
      "Epoch 1700 Done\n",
      "Learning rate:  5.558643690939411e-05\n",
      "Epoch 1800 Done\n",
      "Learning rate:  5.26592943654555e-05\n",
      "Epoch 1900 Done\n",
      "Learning rate:  5.002501250625312e-05\n",
      "Epoch 2000 Done\n",
      "Learning rate:  4.764173415912339e-05\n",
      "Validation Accuracy: 59.31%\n",
      "Testing params:  {'learning_rate': 0.001, 'keep_prob': 0.8, 'decay_rate': 0.0, 'beta2': 0.999, 'beta1': 0.9, 'batch_size': 128}\n",
      "Epoch 100 Done\n",
      "Learning rate:  0.001\n",
      "Epoch 200 Done\n",
      "Learning rate:  0.001\n",
      "Epoch 300 Done\n",
      "Learning rate:  0.001\n",
      "Epoch 400 Done\n",
      "Learning rate:  0.001\n",
      "Epoch 500 Done\n",
      "Learning rate:  0.001\n",
      "Epoch 600 Done\n",
      "Learning rate:  0.001\n",
      "Epoch 700 Done\n",
      "Learning rate:  0.001\n",
      "Epoch 800 Done\n",
      "Learning rate:  0.001\n",
      "Epoch 900 Done\n",
      "Learning rate:  0.001\n",
      "Epoch 1000 Done\n",
      "Learning rate:  0.001\n",
      "Epoch 1100 Done\n",
      "Learning rate:  0.001\n",
      "Epoch 1200 Done\n",
      "Learning rate:  0.001\n",
      "Epoch 1300 Done\n",
      "Learning rate:  0.001\n",
      "Epoch 1400 Done\n",
      "Learning rate:  0.001\n",
      "Epoch 1500 Done\n",
      "Learning rate:  0.001\n",
      "Epoch 1600 Done\n",
      "Learning rate:  0.001\n",
      "Epoch 1700 Done\n",
      "Learning rate:  0.001\n",
      "Epoch 1800 Done\n",
      "Learning rate:  0.001\n",
      "Epoch 1900 Done\n",
      "Learning rate:  0.001\n",
      "Epoch 2000 Done\n",
      "Learning rate:  0.001\n",
      "Validation Accuracy: 60.84%\n",
      "Testing params:  {'learning_rate': 0.01, 'keep_prob': 0.9, 'decay_rate': 0.0, 'beta2': 0.995, 'beta1': 0.95, 'batch_size': 64}\n",
      "Epoch 100 Done\n",
      "Learning rate:  0.01\n",
      "Epoch 200 Done\n",
      "Learning rate:  0.01\n",
      "Epoch 300 Done\n",
      "Learning rate:  0.01\n",
      "Epoch 400 Done\n",
      "Learning rate:  0.01\n",
      "Epoch 500 Done\n",
      "Learning rate:  0.01\n",
      "Epoch 600 Done\n",
      "Learning rate:  0.01\n",
      "Epoch 700 Done\n",
      "Learning rate:  0.01\n",
      "Epoch 800 Done\n",
      "Learning rate:  0.01\n",
      "Epoch 900 Done\n",
      "Learning rate:  0.01\n",
      "Epoch 1000 Done\n",
      "Learning rate:  0.01\n",
      "Epoch 1100 Done\n",
      "Learning rate:  0.01\n",
      "Epoch 1200 Done\n",
      "Learning rate:  0.01\n",
      "Epoch 1300 Done\n",
      "Learning rate:  0.01\n",
      "Epoch 1400 Done\n",
      "Learning rate:  0.01\n",
      "Epoch 1500 Done\n",
      "Learning rate:  0.01\n",
      "Epoch 1600 Done\n",
      "Learning rate:  0.01\n",
      "Epoch 1700 Done\n",
      "Learning rate:  0.01\n",
      "Epoch 1800 Done\n",
      "Learning rate:  0.01\n",
      "Epoch 1900 Done\n",
      "Learning rate:  0.01\n",
      "Epoch 2000 Done\n",
      "Learning rate:  0.01\n",
      "Validation Accuracy: 61.19%\n",
      "Testing params:  {'learning_rate': 0.1, 'keep_prob': 0.8, 'decay_rate': 0.01, 'beta2': 0.995, 'beta1': 0.9, 'batch_size': 128}\n",
      "Epoch 100 Done\n",
      "Learning rate:  0.05025125628140703\n",
      "Epoch 200 Done\n",
      "Learning rate:  0.033444816053511704\n",
      "Epoch 300 Done\n",
      "Learning rate:  0.02506265664160401\n",
      "Epoch 400 Done\n",
      "Learning rate:  0.02004008016032064\n",
      "Epoch 500 Done\n",
      "Learning rate:  0.01669449081803005\n",
      "Epoch 600 Done\n",
      "Learning rate:  0.01430615164520744\n",
      "Epoch 700 Done\n",
      "Learning rate:  0.01251564455569462\n",
      "Epoch 800 Done\n",
      "Learning rate:  0.011123470522803115\n",
      "Epoch 900 Done\n",
      "Learning rate:  0.01001001001001001\n",
      "Epoch 1000 Done\n",
      "Learning rate:  0.009099181073703366\n",
      "Epoch 1100 Done\n",
      "Learning rate:  0.008340283569641367\n",
      "Epoch 1200 Done\n",
      "Learning rate:  0.007698229407236336\n",
      "Epoch 1300 Done\n",
      "Learning rate:  0.0071479628305932815\n",
      "Epoch 1400 Done\n",
      "Learning rate:  0.006671114076050701\n",
      "Epoch 1500 Done\n",
      "Learning rate:  0.006253908692933083\n",
      "Epoch 1600 Done\n",
      "Learning rate:  0.005885815185403178\n",
      "Epoch 1700 Done\n",
      "Learning rate:  0.005558643690939411\n",
      "Epoch 1800 Done\n",
      "Learning rate:  0.00526592943654555\n",
      "Epoch 1900 Done\n",
      "Learning rate:  0.0050025012506253125\n",
      "Epoch 2000 Done\n",
      "Learning rate:  0.004764173415912339\n",
      "Validation Accuracy: 63.64%\n",
      "Testing params:  {'learning_rate': 0.001, 'keep_prob': 0.7, 'decay_rate': 0.001, 'beta2': 0.995, 'beta1': 0.9, 'batch_size': 64}\n",
      "Epoch 100 Done\n",
      "Learning rate:  0.0009099181073703368\n",
      "Epoch 200 Done\n",
      "Learning rate:  0.0008340283569641367\n",
      "Epoch 300 Done\n",
      "Learning rate:  0.0007698229407236335\n",
      "Epoch 400 Done\n",
      "Learning rate:  0.0007147962830593281\n",
      "Epoch 500 Done\n",
      "Learning rate:  0.0006671114076050701\n",
      "Epoch 600 Done\n",
      "Learning rate:  0.0006253908692933083\n",
      "Epoch 700 Done\n",
      "Learning rate:  0.0005885815185403178\n",
      "Epoch 800 Done\n",
      "Learning rate:  0.0005558643690939412\n",
      "Epoch 900 Done\n",
      "Learning rate:  0.000526592943654555\n",
      "Epoch 1000 Done\n",
      "Learning rate:  0.0005002501250625312\n",
      "Epoch 1100 Done\n",
      "Learning rate:  0.0004764173415912339\n",
      "Epoch 1200 Done\n",
      "Learning rate:  0.0004547521600727604\n",
      "Epoch 1300 Done\n",
      "Learning rate:  0.00043497172683775554\n",
      "Epoch 1400 Done\n",
      "Learning rate:  0.00041684035014589413\n",
      "Epoch 1500 Done\n",
      "Learning rate:  0.0004001600640256102\n",
      "Epoch 1600 Done\n",
      "Learning rate:  0.0003847633705271258\n",
      "Epoch 1700 Done\n",
      "Learning rate:  0.0003705075954057058\n",
      "Epoch 1800 Done\n",
      "Learning rate:  0.0003572704537334763\n",
      "Epoch 1900 Done\n",
      "Learning rate:  0.0003449465332873405\n",
      "Epoch 2000 Done\n",
      "Learning rate:  0.00033344448149383126\n",
      "Validation Accuracy: 60.88%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import ParameterSampler, train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "param_grid = {\n",
    "    'learning_rate': [0.001, 0.01, 0.1],\n",
    "    'keep_prob': [0.7, 0.8, 0.9],\n",
    "    'beta1': [0.9, 0.95],\n",
    "    'beta2': [0.999, 0.995],\n",
    "    'decay_rate': [0.0, 0.001, 0.01],\n",
    "    'batch_size': [32, 64, 128]\n",
    "}\n",
    "\n",
    "\n",
    "param_samples = list(ParameterSampler(param_grid, n_iter=10, random_state=42))\n",
    "\n",
    "best_accuracy = 0\n",
    "best_params = {}\n",
    "\n",
    "params = init_params(X.shape[1])\n",
    "\n",
    "for params_sample in param_samples:\n",
    "    print(\"Testing params: \", params_sample)\n",
    "\n",
    "    model_params = model(\n",
    "        X_train, y_train,\n",
    "        params=params,\n",
    "        epochs=2000,\n",
    "        learning_rate=params_sample['learning_rate'],\n",
    "        keep_prob=params_sample['keep_prob'],\n",
    "        beta1=params_sample['beta1'],\n",
    "        beta2=params_sample['beta2'],\n",
    "        decay_rate=params_sample['decay_rate']\n",
    "    )\n",
    "\n",
    "    y_pred, _ = predict(X_val, model_params)\n",
    "    accuracy = np.mean((y_pred > 0.5) == y_val) * 100\n",
    "    print(f\"Validation Accuracy: {accuracy:.2f}%\")\n",
    "    \n",
    "    # Track best params\n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        best_params = params_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100 Done\n",
      "Learning rate:  0.1\n",
      "Epoch 200 Done\n",
      "Learning rate:  0.1\n",
      "Epoch 300 Done\n",
      "Learning rate:  0.1\n",
      "Epoch 400 Done\n",
      "Learning rate:  0.1\n",
      "Epoch 500 Done\n",
      "Learning rate:  0.1\n",
      "Epoch 600 Done\n",
      "Learning rate:  0.1\n",
      "Epoch 700 Done\n",
      "Learning rate:  0.1\n",
      "Epoch 800 Done\n",
      "Learning rate:  0.1\n",
      "Epoch 900 Done\n",
      "Learning rate:  0.1\n",
      "Epoch 1000 Done\n",
      "Learning rate:  0.1\n",
      "Epoch 1100 Done\n",
      "Learning rate:  0.1\n",
      "Epoch 1200 Done\n",
      "Learning rate:  0.1\n",
      "Epoch 1300 Done\n",
      "Learning rate:  0.1\n",
      "Epoch 1400 Done\n",
      "Learning rate:  0.1\n",
      "Epoch 1500 Done\n",
      "Learning rate:  0.1\n",
      "Epoch 1600 Done\n",
      "Learning rate:  0.1\n",
      "Epoch 1700 Done\n",
      "Learning rate:  0.1\n",
      "Epoch 1800 Done\n",
      "Learning rate:  0.1\n",
      "Epoch 1900 Done\n",
      "Learning rate:  0.1\n",
      "Epoch 2000 Done\n",
      "Learning rate:  0.1\n",
      "Epoch 2100 Done\n",
      "Learning rate:  0.1\n",
      "Epoch 2200 Done\n",
      "Learning rate:  0.1\n",
      "Epoch 2300 Done\n",
      "Learning rate:  0.1\n",
      "Epoch 2400 Done\n",
      "Learning rate:  0.1\n",
      "Epoch 2500 Done\n",
      "Learning rate:  0.1\n",
      "Epoch 2600 Done\n",
      "Learning rate:  0.1\n",
      "Epoch 2700 Done\n",
      "Learning rate:  0.1\n",
      "Epoch 2800 Done\n",
      "Learning rate:  0.1\n",
      "Epoch 2900 Done\n",
      "Learning rate:  0.1\n",
      "Epoch 3000 Done\n",
      "Learning rate:  0.1\n",
      "Epoch 3100 Done\n",
      "Learning rate:  0.1\n",
      "Epoch 3200 Done\n",
      "Learning rate:  0.1\n",
      "Epoch 3300 Done\n",
      "Learning rate:  0.1\n",
      "Epoch 3400 Done\n",
      "Learning rate:  0.1\n",
      "Epoch 3500 Done\n",
      "Learning rate:  0.1\n",
      "Epoch 3600 Done\n",
      "Learning rate:  0.1\n",
      "Epoch 3700 Done\n",
      "Learning rate:  0.1\n",
      "Epoch 3800 Done\n",
      "Learning rate:  0.1\n",
      "Epoch 3900 Done\n",
      "Learning rate:  0.1\n",
      "Epoch 4000 Done\n",
      "Learning rate:  0.1\n",
      "Epoch 4100 Done\n",
      "Learning rate:  0.1\n",
      "Epoch 4200 Done\n",
      "Learning rate:  0.1\n",
      "Epoch 4300 Done\n",
      "Learning rate:  0.1\n",
      "Epoch 4400 Done\n",
      "Learning rate:  0.1\n",
      "Epoch 4500 Done\n",
      "Learning rate:  0.1\n",
      "Epoch 4600 Done\n",
      "Learning rate:  0.1\n",
      "Epoch 4700 Done\n",
      "Learning rate:  0.1\n",
      "Epoch 4800 Done\n",
      "Learning rate:  0.1\n",
      "Epoch 4900 Done\n",
      "Learning rate:  0.1\n",
      "Epoch 5000 Done\n",
      "Learning rate:  0.1\n"
     ]
    }
   ],
   "source": [
    "params = init_params(X.shape[1])\n",
    "params = model(X_train, y_train, params, 5000, **best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 81.18%\n"
     ]
    }
   ],
   "source": [
    "y_pred, cahce = predict(X_test, params)\n",
    "\n",
    "accuracy = np.mean((y_pred > 0.5) == y_test) *100\n",
    "print(f\"Accuracy: {accuracy:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
